# Filesystem Data Source - Konzept

## √úbersicht

Dieses Konzept beschreibt die Implementierung einer Dateisystem-basierten Datenquelle f√ºr das mDW RAG-System. Benutzer k√∂nnen beliebig viele Datenquellen konfigurieren, wobei jede Datenquelle mehrere Verzeichnisse umfassen kann. Jede Datenquelle wird automatisch einer eigenen Collection zugeordnet, was gezielte RAG-Abfragen erm√∂glicht.

---

## Architektur-Entscheidungen

### Implementierung: In Hypatia als Subsystem

Die Datenquellen-Verwaltung wird **in Hypatia integriert**, nicht als separater Service.

| Aspekt | Entscheidung | Begr√ºndung |
|--------|--------------|------------|
| **Ort** | Hypatia (RAG Service) | Enge Kopplung mit Ingestion-Pipeline |
| **Struktur** | Subsystem unter `internal/hypatia/datasource/` | Klare Modularisierung |
| **Kommunikation** | Direkte Funktionsaufrufe | Kein gRPC-Overhead |
| **Deployment** | Teil von Hypatia | Ein Service weniger zu verwalten |

**Paketstruktur in Hypatia:**

```
internal/hypatia/
‚îú‚îÄ‚îÄ server/              # gRPC/HTTP Server (existiert)
‚îú‚îÄ‚îÄ service/             # RAG Business Logic (existiert)
‚îú‚îÄ‚îÄ vectorstore/         # Qdrant Integration (existiert)
‚îú‚îÄ‚îÄ datasource/          # NEU: Datenquellen-Subsystem
‚îÇ   ‚îú‚îÄ‚îÄ manager.go       # DataSourceManager (orchestriert alles)
‚îÇ   ‚îú‚îÄ‚îÄ types.go         # Interfaces & Types
‚îÇ   ‚îú‚îÄ‚îÄ filesystem/      # Filesystem-Implementierung
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ source.go    # FilesystemSource
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ watcher.go   # fsnotify Wrapper
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scanner.go   # Directory Scanner
‚îÇ   ‚îî‚îÄ‚îÄ state/           # Persistenz
‚îÇ       ‚îî‚îÄ‚îÄ sqlite.go    # SQLite Repository
‚îî‚îÄ‚îÄ parser/              # Dokument-Parser (existiert/erweitern)
```

### Gesch√§tzter Umfang

| Komponente | Zeilen (ca.) | Komplexit√§t |
|------------|--------------|-------------|
| **Interfaces & Types** | 200-300 | Niedrig |
| **DataSourceManager** | 300-400 | Mittel |
| **FilesystemSource** | 500-700 | Mittel |
| **FileWatcher (fsnotify)** | 300-400 | Mittel |
| **Scanner** | 200-300 | Niedrig |
| **SQLite State** | 400-500 | Mittel |
| **Parser-Erweiterungen** | 300-500 | Mittel |
| **gRPC API** | 200-300 | Niedrig |
| **REST API** | 200-300 | Niedrig |
| **Tests** | 1000-1500 | - |
| **Gesamt** | **~4000-5000** | **Mittel** |

### Speicherort der Konfiguration

Datenquellen-Konfiguration und Datei-Status werden in **SQLite** gespeichert:

```
~/.mdw/
‚îú‚îÄ‚îÄ config.toml              # Globale Konfiguration (optional)
‚îî‚îÄ‚îÄ hypatia/
    ‚îî‚îÄ‚îÄ datasources.db       # SQLite Datenbank
```

**Warum SQLite?**

| Alternative | Problem |
|-------------|---------|
| config.toml | Nicht f√ºr dynamische Daten geeignet |
| JSON-Datei | Keine Transaktionen, Race Conditions |
| Qdrant | Falscher Zweck (Vektoren, nicht Config) |
| PostgreSQL | Overkill, externe Abh√§ngigkeit |

**SQLite Vorteile:**
- Eingebettet, keine externe Abh√§ngigkeit
- ACID-Transaktionen
- Performant f√ºr diese Datenmenge
- Einfache Backup/Restore
- Cross-Platform

**Datenbank-Schema:**

```sql
-- Datenquellen
CREATE TABLE data_sources (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL UNIQUE,
    collection_name TEXT NOT NULL UNIQUE,
    type TEXT NOT NULL DEFAULT 'filesystem',
    config JSON NOT NULL,
    status TEXT NOT NULL DEFAULT 'active',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- √úberwachte Pfade pro Datenquelle
CREATE TABLE source_paths (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_id TEXT NOT NULL REFERENCES data_sources(id) ON DELETE CASCADE,
    path TEXT NOT NULL,
    recursive BOOLEAN DEFAULT TRUE,
    include_patterns JSON,  -- ["*.md", "*.pdf"]
    exclude_patterns JSON,  -- ["*.tmp", ".git/*"]
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(source_id, path)
);

-- Datei-Status (f√ºr Change Detection)
CREATE TABLE file_states (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_id TEXT NOT NULL REFERENCES data_sources(id) ON DELETE CASCADE,
    path TEXT NOT NULL,
    hash TEXT NOT NULL,
    size INTEGER NOT NULL,
    modified_at TIMESTAMP NOT NULL,
    indexed_at TIMESTAMP NOT NULL,
    document_id TEXT,  -- Referenz in Qdrant
    status TEXT NOT NULL DEFAULT 'pending',
    error_message TEXT,
    UNIQUE(source_id, path)
);

-- Sync-Historie
CREATE TABLE sync_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_id TEXT NOT NULL REFERENCES data_sources(id) ON DELETE CASCADE,
    started_at TIMESTAMP NOT NULL,
    completed_at TIMESTAMP,
    files_added INTEGER DEFAULT 0,
    files_updated INTEGER DEFAULT 0,
    files_deleted INTEGER DEFAULT 0,
    errors JSON,
    status TEXT NOT NULL  -- 'running', 'completed', 'failed'
);

-- Indices f√ºr Performance
CREATE INDEX idx_file_states_source ON file_states(source_id);
CREATE INDEX idx_file_states_status ON file_states(status);
CREATE INDEX idx_file_states_hash ON file_states(hash);
CREATE INDEX idx_sync_history_source ON sync_history(source_id);
```

---

## Kernprinzip: 1 Datenquelle = 1 Collection

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Datenquellen-Hierarchie                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ DataSource: "Projekt Alpha"                                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ Verzeichnis: /home/user/projects/alpha/docs             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ Verzeichnis: /home/user/projects/alpha/specs            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ ‚Üí Collection: "projekt-alpha" (automatisch)             ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ DataSource: "Pers√∂nliche Notizen"                            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ Verzeichnis: /home/user/Notes                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ ‚Üí Collection: "persoenliche-notizen" (automatisch)      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ DataSource: "Technische Dokumentation"                       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ Verzeichnis: /opt/docs/manuals                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ Verzeichnis: /opt/docs/references                       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îú‚îÄ‚îÄ Verzeichnis: /opt/docs/tutorials                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ ‚Üí Collection: "technische-dokumentation" (automatisch)  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Bei RAG-Abfragen:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  "Wie konfiguriere ich den Server?"                                 ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  Suche in:                                                          ‚îÇ
‚îÇ  (‚Ä¢) Alle Datenquellen                                              ‚îÇ
‚îÇ  ( ) Nur ausgew√§hlte:                                               ‚îÇ
‚îÇ      [x] Projekt Alpha                                              ‚îÇ
‚îÇ      [ ] Pers√∂nliche Notizen                                        ‚îÇ
‚îÇ      [x] Technische Dokumentation                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Vorteile dieses Modells

| Vorteil | Beschreibung |
|---------|--------------|
| **Kontextuelle Suche** | Gezielte Suche in relevanten Bereichen |
| **Performance** | Kleinerer Suchraum = schnellere Antworten |
| **Datentrennung** | Privat vs. Gesch√§ftlich vs. Projekt-spezifisch |
| **Granulare Verwaltung** | Einzelne Quellen pausieren/l√∂schen/synchronisieren |
| **Logische Gruppierung** | Zusammengeh√∂rige Verzeichnisse in einer Quelle |
| **Flexibilit√§t** | Multi-Collection-Suche bei Bedarf |

---

## Architektur

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                              mDW Platform                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                    Hypatia (RAG Service)                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                   DataSource Manager                         ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ Filesystem  ‚îÇ ‚îÇ   S3/Minio  ‚îÇ ‚îÇ   WebDAV    ‚îÇ  ...       ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ   Source    ‚îÇ ‚îÇ   Source    ‚îÇ ‚îÇ   Source    ‚îÇ            ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ            ‚îÇ                                                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                    Sync Engine                               ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  Watcher  ‚îÇ  ‚îÇ  Scanner  ‚îÇ  ‚îÇ  Differ   ‚îÇ               ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                              ‚îÇ                                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                Document Processor                            ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  PDF   ‚îÇ ‚îÇ  DOCX  ‚îÇ ‚îÇ   MD   ‚îÇ ‚îÇ  TXT   ‚îÇ ‚îÇ  HTML  ‚îÇ   ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ Parser ‚îÇ ‚îÇ Parser ‚îÇ ‚îÇ Parser ‚îÇ ‚îÇ Parser ‚îÇ ‚îÇ Parser ‚îÇ   ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                              ‚îÇ                                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ              Ingest Pipeline (bestehend)                     ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Chunking ‚Üí Embedding ‚Üí Vector Storage                       ‚îÇ ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Komponenten

### 1. DataSource Interface

Alle Datenquellen implementieren ein gemeinsames Interface:

```go
// DataSource definiert eine Datenquelle f√ºr Dokumente
type DataSource interface {
    // ID gibt die eindeutige Kennung der Datenquelle zur√ºck
    ID() string

    // Type gibt den Typ der Datenquelle zur√ºck (filesystem, s3, webdav, etc.)
    Type() string

    // Name gibt den benutzerdefinierten Namen zur√ºck
    Name() string

    // Status gibt den aktuellen Status der Datenquelle zur√ºck
    Status() DataSourceStatus

    // Scan f√ºhrt einen vollst√§ndigen Scan durch
    Scan(ctx context.Context) (*ScanResult, error)

    // Watch startet die Echtzeit-√úberwachung
    Watch(ctx context.Context, handler ChangeHandler) error

    // StopWatch beendet die √úberwachung
    StopWatch() error

    // GetFile l√§dt eine einzelne Datei
    GetFile(ctx context.Context, path string) (*FileContent, error)

    // Close schlie√üt die Datenquelle
    Close() error
}

type DataSourceStatus string

const (
    DataSourceStatusActive   DataSourceStatus = "active"
    DataSourceStatusPaused   DataSourceStatus = "paused"
    DataSourceStatusScanning DataSourceStatus = "scanning"
    DataSourceStatusError    DataSourceStatus = "error"
)

type ChangeHandler func(event ChangeEvent)

type ChangeEvent struct {
    Type      ChangeType
    Path      string
    OldPath   string  // F√ºr Umbenennungen
    Timestamp time.Time
    FileInfo  FileInfo
}

type ChangeType string

const (
    ChangeTypeCreated  ChangeType = "created"
    ChangeTypeModified ChangeType = "modified"
    ChangeTypeDeleted  ChangeType = "deleted"
    ChangeTypeRenamed  ChangeType = "renamed"
)
```

### 2. Filesystem DataSource

```go
// FilesystemConfig konfiguriert eine Dateisystem-Datenquelle
type FilesystemConfig struct {
    ID          string            `json:"id"`
    Name        string            `json:"name"`
    Paths       []string          `json:"paths"`           // √úberwachte Verzeichnisse
    Recursive   bool              `json:"recursive"`       // Unterverzeichnisse einschlie√üen
    Extensions  []string          `json:"extensions"`      // Erlaubte Dateiendungen (leer = alle)
    Exclude     []string          `json:"exclude"`         // Ausgeschlossene Muster (glob)
    MaxFileSize int64             `json:"max_file_size"`   // Max. Dateigr√∂√üe in Bytes
    Collection  string            `json:"collection"`      // Ziel-Collection
    Metadata    map[string]string `json:"metadata"`        // Zus√§tzliche Metadaten
    SyncMode    SyncMode          `json:"sync_mode"`       // watch, poll, manual
    PollInterval time.Duration    `json:"poll_interval"`   // F√ºr Poll-Modus
}

type SyncMode string

const (
    SyncModeWatch  SyncMode = "watch"   // Echtzeit via fsnotify
    SyncModePoll   SyncMode = "poll"    // Periodisches Polling
    SyncModeManual SyncMode = "manual"  // Nur manuell
)
```

### 3. File State Tracking

Zur Erkennung von √Ñnderungen wird der Zustand aller Dateien in einer lokalen Datenbank gespeichert:

```go
// FileState speichert den Zustand einer Datei
type FileState struct {
    ID           string    `db:"id"`            // UUID
    DataSourceID string    `db:"datasource_id"` // Zugeh√∂rige Datenquelle
    Path         string    `db:"path"`          // Relativer Pfad
    AbsolutePath string    `db:"absolute_path"` // Absoluter Pfad
    Hash         string    `db:"hash"`          // SHA-256 des Inhalts
    Size         int64     `db:"size"`          // Dateigr√∂√üe
    ModTime      time.Time `db:"mod_time"`      // √Ñnderungszeit
    DocumentID   string    `db:"document_id"`   // Referenz zum Dokument in Hypatia
    Status       FileStatus `db:"status"`       // indexed, pending, error
    LastSynced   time.Time `db:"last_synced"`   // Letzte Synchronisation
    ErrorMessage string    `db:"error_message"` // Fehlermeldung bei Status=error
    CreatedAt    time.Time `db:"created_at"`
    UpdatedAt    time.Time `db:"updated_at"`
}

type FileStatus string

const (
    FileStatusPending  FileStatus = "pending"   // Noch nicht verarbeitet
    FileStatusIndexed  FileStatus = "indexed"   // Erfolgreich indiziert
    FileStatusError    FileStatus = "error"     // Fehler bei Verarbeitung
    FileStatusDeleted  FileStatus = "deleted"   // Datei wurde gel√∂scht
)
```

---

## Synchronisations-Logik

### Initiales Scannen

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Initial Scan Workflow                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                         ‚îÇ
‚îÇ   1. Verzeichnis hinzuf√ºgen                                            ‚îÇ
‚îÇ          ‚îÇ                                                              ‚îÇ
‚îÇ          ‚ñº                                                              ‚îÇ
‚îÇ   2. Rekursives Scannen aller Dateien                                  ‚îÇ
‚îÇ          ‚îÇ                                                              ‚îÇ
‚îÇ          ‚ñº                                                              ‚îÇ
‚îÇ   3. Filter anwenden (Extensions, Exclude, MaxSize)                    ‚îÇ
‚îÇ          ‚îÇ                                                              ‚îÇ
‚îÇ          ‚ñº                                                              ‚îÇ
‚îÇ   4. Hash berechnen f√ºr jede Datei                                     ‚îÇ
‚îÇ          ‚îÇ                                                              ‚îÇ
‚îÇ          ‚ñº                                                              ‚îÇ
‚îÇ   5. FileState in DB speichern (Status: pending)                       ‚îÇ
‚îÇ          ‚îÇ                                                              ‚îÇ
‚îÇ          ‚ñº                                                              ‚îÇ
‚îÇ   6. Dateien zur Ingest-Queue hinzuf√ºgen                               ‚îÇ
‚îÇ          ‚îÇ                                                              ‚îÇ
‚îÇ          ‚ñº                                                              ‚îÇ
‚îÇ   7. Async Processing: Parse ‚Üí Chunk ‚Üí Embed ‚Üí Store                   ‚îÇ
‚îÇ          ‚îÇ                                                              ‚îÇ
‚îÇ          ‚ñº                                                              ‚îÇ
‚îÇ   8. FileState aktualisieren (Status: indexed, DocumentID setzen)      ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### √Ñnderungserkennung

```go
// SyncResult enth√§lt das Ergebnis einer Synchronisation
type SyncResult struct {
    DataSourceID string
    StartTime    time.Time
    EndTime      time.Time

    // Statistiken
    FilesScanned   int
    FilesAdded     int
    FilesModified  int
    FilesDeleted   int
    FilesUnchanged int
    FilesErrored   int

    // Details
    Changes []ChangeDetail
    Errors  []SyncError
}

type ChangeDetail struct {
    Path       string
    ChangeType ChangeType
    OldHash    string
    NewHash    string
    DocumentID string
}
```

### Synchronisations-Algorithmus

```
F√ºr jede Datei im Verzeichnis:
  1. Existiert FileState in DB?
     ‚îÇ
     ‚îú‚îÄ NEIN ‚Üí Neue Datei
     ‚îÇ         ‚Üí FileState erstellen
     ‚îÇ         ‚Üí Zur Ingest-Queue hinzuf√ºgen
     ‚îÇ
     ‚îî‚îÄ JA ‚Üí Pr√ºfe √Ñnderung
             ‚îÇ
             ‚îú‚îÄ ModTime oder Size ge√§ndert?
             ‚îÇ   ‚îÇ
             ‚îÇ   ‚îú‚îÄ JA ‚Üí Hash berechnen
             ‚îÇ   ‚îÇ       ‚îÇ
             ‚îÇ   ‚îÇ       ‚îú‚îÄ Hash unterschiedlich?
             ‚îÇ   ‚îÇ       ‚îÇ   ‚îÇ
             ‚îÇ   ‚îÇ       ‚îÇ   ‚îú‚îÄ JA ‚Üí Datei ge√§ndert
             ‚îÇ   ‚îÇ       ‚îÇ   ‚îÇ       ‚Üí Altes Dokument l√∂schen
             ‚îÇ   ‚îÇ       ‚îÇ   ‚îÇ       ‚Üí Neu ingestieren
             ‚îÇ   ‚îÇ       ‚îÇ   ‚îÇ
             ‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ NEIN ‚Üí Nur Metadaten ge√§ndert
             ‚îÇ   ‚îÇ       ‚îÇ             ‚Üí FileState aktualisieren
             ‚îÇ   ‚îÇ       ‚îÇ
             ‚îÇ   ‚îÇ       ‚îî‚îÄ [Optimierung: Bei kleinen Dateien]
             ‚îÇ   ‚îÇ
             ‚îÇ   ‚îî‚îÄ NEIN ‚Üí Unver√§ndert
             ‚îÇ
             ‚îî‚îÄ [weiter]

F√ºr jeden FileState in DB ohne entsprechende Datei:
  ‚Üí Datei wurde gel√∂scht
  ‚Üí Dokument aus Hypatia l√∂schen
  ‚Üí FileState als deleted markieren oder l√∂schen
```

---

## Cross-Platform-Unterst√ºtzung

### File Watching

| Feature | Windows | macOS | Linux |
|---------|---------|-------|-------|
| **Library** | `fsnotify` | `fsnotify` | `fsnotify` |
| **Backend** | ReadDirectoryChangesW | FSEvents / kqueue | inotify |
| **Rekursiv** | ‚úì Nativ | ‚úì FSEvents | ‚ö†Ô∏è Manuell |
| **Max Watches** | ~10.000 | Unbegrenzt | ~8.192 (konfigurierbar) |

### Pfad-Handling

```go
// PathNormalizer normalisiert Pfade f√ºr alle Plattformen
type PathNormalizer struct{}

func (n *PathNormalizer) Normalize(path string) string {
    // Immer Forward-Slashes verwenden (intern)
    path = filepath.ToSlash(path)

    // Trailing Slash entfernen
    path = strings.TrimSuffix(path, "/")

    return path
}

func (n *PathNormalizer) ToNative(path string) string {
    return filepath.FromSlash(path)
}

func (n *PathNormalizer) IsAbsolute(path string) bool {
    // Windows: C:\, D:\, etc.
    if runtime.GOOS == "windows" {
        if len(path) >= 2 && path[1] == ':' {
            return true
        }
    }
    return filepath.IsAbs(path)
}
```

### Bekannte Plattform-Unterschiede

| Aspekt | Windows | macOS | Linux |
|--------|---------|-------|-------|
| **Pfad-Separator** | `\` | `/` | `/` |
| **Case-Sensitivity** | Nein | Standard Nein (HFS+) | Ja |
| **Symlinks** | NTFS ab Vista | ‚úì | ‚úì |
| **Max Pfadl√§nge** | 260 (erweiterbar) | 1024 | 4096 |
| **Versteckte Dateien** | Attribut | `.`-Prefix | `.`-Prefix |
| **Sperrung** | Exklusiv beim Schreiben | Advisory | Advisory |

### Symlink-Handling

```go
type SymlinkPolicy string

const (
    SymlinkPolicyFollow SymlinkPolicy = "follow"  // Symlinks folgen
    SymlinkPolicyIgnore SymlinkPolicy = "ignore"  // Symlinks ignorieren
    SymlinkPolicyError  SymlinkPolicy = "error"   // Fehler bei Symlinks
)
```

---

## Unterst√ºtzte Dateiformate

### Phase 1 (Initial)

| Format | Extension | Parser | Bibliothek |
|--------|-----------|--------|------------|
| Plain Text | `.txt` | Native | Go stdlib |
| Markdown | `.md` | Native | goldmark |
| HTML | `.html`, `.htm` | Native | x/net/html |
| JSON | `.json` | Native | Go stdlib |
| YAML | `.yaml`, `.yml` | Native | gopkg.in/yaml.v3 |
| XML | `.xml` | Native | encoding/xml |

### Phase 2 (Erweitert)

| Format | Extension | Parser | Bibliothek |
|--------|-----------|--------|------------|
| PDF | `.pdf` | Extern | pdfcpu / poppler |
| DOCX | `.docx` | Extern | unioffice |
| XLSX | `.xlsx` | Extern | excelize |
| PPTX | `.pptx` | Extern | unioffice |
| ODT | `.odt` | Extern | Custom ZIP parser |
| EPUB | `.epub` | Extern | go-epub |
| RTF | `.rtf` | Extern | Custom parser |

### Phase 3 (Code & Speziell)

| Format | Extension | Parser | Beschreibung |
|--------|-----------|--------|--------------|
| Source Code | `.go`, `.py`, `.js`, etc. | Native | Mit Syntax-Metadata |
| Jupyter | `.ipynb` | Native | JSON-basiert |
| CSV | `.csv` | Native | encoding/csv |
| Log Files | `.log` | Native | Zeilenbasiert |

### Parser Interface

```go
// DocumentParser parsed Dateien zu Text
type DocumentParser interface {
    // Extensions gibt die unterst√ºtzten Dateiendungen zur√ºck
    Extensions() []string

    // Parse extrahiert Text und Metadaten aus einer Datei
    Parse(ctx context.Context, reader io.Reader, filename string) (*ParseResult, error)

    // CanParse pr√ºft, ob die Datei verarbeitet werden kann
    CanParse(filename string, mimeType string) bool
}

type ParseResult struct {
    Content   string            // Extrahierter Text
    Title     string            // Dokumenttitel (falls vorhanden)
    Author    string            // Autor (falls vorhanden)
    Created   time.Time         // Erstellungsdatum (falls vorhanden)
    Metadata  map[string]string // Zus√§tzliche Metadaten
    Sections  []Section         // Strukturierte Abschnitte (optional)
    Language  string            // Erkannte Sprache
    PageCount int               // Seitenzahl (f√ºr PDFs etc.)
}

type Section struct {
    Title   string
    Content string
    Level   int // Hierarchieebene (1 = H1, 2 = H2, etc.)
}
```

---

## API-Design

### gRPC Service (Hypatia)

```protobuf
service HypatiaService {
    // Bestehende RPCs...

    // === DataSource Management ===

    // Datenquelle hinzuf√ºgen
    rpc AddDataSource(AddDataSourceRequest) returns (DataSource);

    // Datenquelle aktualisieren
    rpc UpdateDataSource(UpdateDataSourceRequest) returns (DataSource);

    // Datenquelle entfernen
    rpc RemoveDataSource(RemoveDataSourceRequest) returns (google.protobuf.Empty);

    // Datenquellen auflisten
    rpc ListDataSources(ListDataSourcesRequest) returns (ListDataSourcesResponse);

    // Datenquelle abrufen
    rpc GetDataSource(GetDataSourceRequest) returns (DataSource);

    // === Sync Operations ===

    // Manuellen Scan starten
    rpc TriggerSync(TriggerSyncRequest) returns (SyncStatus);

    // Sync-Status abrufen
    rpc GetSyncStatus(GetSyncStatusRequest) returns (SyncStatus);

    // Sync-Historie abrufen
    rpc GetSyncHistory(GetSyncHistoryRequest) returns (GetSyncHistoryResponse);

    // === File Operations ===

    // Dateistatus abrufen
    rpc GetFileStatus(GetFileStatusRequest) returns (FileStatus);

    // Dateien einer Datenquelle auflisten
    rpc ListDataSourceFiles(ListDataSourceFilesRequest) returns (ListDataSourceFilesResponse);
}
```

### REST API (Kant)

```yaml
paths:
  # === Datenquellen-Management ===
  /api/v1/datasources:
    get:
      summary: Liste aller Datenquellen
      responses:
        200:
          content:
            application/json:
              schema:
                type: object
                properties:
                  datasources:
                    type: array
                    items:
                      $ref: '#/components/schemas/DataSource'
                  total:
                    type: integer

    post:
      summary: Neue Datenquelle hinzuf√ºgen
      description: |
        Erstellt eine neue Datenquelle mit automatischer Collection.
        Die Collection wird aus dem Namen abgeleitet (slugified).
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateDataSourceRequest'
      responses:
        201:
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DataSource'

  /api/v1/datasources/{id}:
    get:
      summary: Datenquelle abrufen
    put:
      summary: Datenquelle aktualisieren
    delete:
      summary: Datenquelle entfernen (inkl. Collection)

  /api/v1/datasources/{id}/paths:
    post:
      summary: Verzeichnis zur Datenquelle hinzuf√ºgen
      requestBody:
        content:
          application/json:
            schema:
              type: object
              properties:
                path:
                  type: string
                recursive:
                  type: boolean
                  default: true
    delete:
      summary: Verzeichnis aus Datenquelle entfernen

  /api/v1/datasources/{id}/sync:
    post:
      summary: Synchronisation starten
      responses:
        202:
          description: Sync gestartet
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/SyncStatus'

    get:
      summary: Sync-Status abrufen

  /api/v1/datasources/{id}/files:
    get:
      summary: Dateien der Datenquelle auflisten
      parameters:
        - name: status
          in: query
          schema:
            type: string
            enum: [pending, indexed, error, deleted]
        - name: limit
          in: query
          schema:
            type: integer
        - name: offset
          in: query
          schema:
            type: integer

  # === Erweiterte Such-API ===
  /api/v1/search:
    post:
      summary: Semantische Suche (erweitert)
      description: |
        Sucht in einer oder mehreren Datenquellen/Collections.
        Ohne `collections` Parameter wird in allen gesucht.
      requestBody:
        content:
          application/json:
            schema:
              type: object
              required:
                - query
              properties:
                query:
                  type: string
                  description: Suchanfrage
                collections:
                  type: array
                  items:
                    type: string
                  description: |
                    Liste der Collection-Namen oder Datenquellen-IDs.
                    Leer = alle Datenquellen durchsuchen.
                top_k:
                  type: integer
                  default: 10
                min_score:
                  type: number
                  default: 0.0
      responses:
        200:
          content:
            application/json:
              schema:
                type: object
                properties:
                  query:
                    type: string
                  results:
                    type: array
                    items:
                      $ref: '#/components/schemas/SearchResult'
                  collections_searched:
                    type: array
                    items:
                      type: string
                  total:
                    type: integer

components:
  schemas:
    DataSource:
      type: object
      properties:
        id:
          type: string
          description: Eindeutige ID der Datenquelle
        type:
          type: string
          enum: [filesystem, s3, webdav]
        name:
          type: string
          description: Benutzerfreundlicher Name
        collection_name:
          type: string
          description: |
            Name der zugeh√∂rigen Collection (automatisch aus name generiert).
            Beispiel: "Projekt Alpha" ‚Üí "projekt-alpha"
        status:
          type: string
          enum: [active, paused, scanning, error]
        paths:
          type: array
          items:
            type: string
          description: Liste der √ºberwachten Verzeichnisse
        config:
          type: object
          # Je nach Typ unterschiedlich
        statistics:
          $ref: '#/components/schemas/DataSourceStats'
        created_at:
          type: string
          format: date-time
        updated_at:
          type: string
          format: date-time

    DataSourceStats:
      type: object
      properties:
        total_files:
          type: integer
        indexed_files:
          type: integer
        pending_files:
          type: integer
        error_files:
          type: integer
        total_size:
          type: integer
          format: int64
        last_sync:
          type: string
          format: date-time

    CreateDataSourceRequest:
      type: object
      required:
        - type
        - name
        - config
      properties:
        type:
          type: string
          enum: [filesystem]
        name:
          type: string
        config:
          $ref: '#/components/schemas/FilesystemConfig'

    FilesystemConfig:
      type: object
      required:
        - paths
      properties:
        paths:
          type: array
          items:
            type: string
          description: Zu √ºberwachende Verzeichnisse
        recursive:
          type: boolean
          default: true
        extensions:
          type: array
          items:
            type: string
          description: Erlaubte Dateiendungen (leer = alle)
        exclude:
          type: array
          items:
            type: string
          description: Auszuschlie√üende Muster (glob)
        max_file_size:
          type: integer
          format: int64
          default: 104857600
          description: Max. Dateigr√∂√üe in Bytes (default 100MB)
        collection:
          type: string
          description: Ziel-Collection
        sync_mode:
          type: string
          enum: [watch, poll, manual]
          default: watch
        poll_interval:
          type: string
          description: Polling-Intervall (z.B. "5m", "1h")
```

---

## Konfiguration

### config.toml

```toml
[hypatia.datasources]
# Aktiviert die DataSource-Funktionalit√§t
enabled = true

# Datenbank f√ºr FileState Tracking
# Pfad relativ zu ~/.mdw/ oder absolut
state_db_path = "~/.mdw/hypatia/datasources.db"

# Standard-Einstellungen f√ºr Filesystem-Quellen
[hypatia.datasources.filesystem]
# Standard-Sync-Modus
default_sync_mode = "watch"

# Standard-Poll-Intervall (f√ºr poll-Modus)
default_poll_interval = "5m"

# Maximale Dateigr√∂√üe (100 MB)
max_file_size = 104857600

# Standard-Ausschl√ºsse
default_exclude = [
    ".*",           # Versteckte Dateien/Ordner
    "node_modules",
    "__pycache__",
    "*.tmp",
    "*.swp",
    "~$*",          # Office Temp-Dateien
]

# Unterst√ºtzte Dateiendungen (leer = alle)
supported_extensions = [
    # Text
    ".txt", ".md", ".markdown",
    # Dokumente
    ".pdf", ".docx", ".doc", ".odt", ".rtf",
    # Daten
    ".json", ".yaml", ".yml", ".xml", ".csv",
    # Web
    ".html", ".htm",
    # Code
    ".go", ".py", ".js", ".ts", ".java", ".rs", ".c", ".cpp",
]

# Parallelit√§t beim Ingestieren
ingest_workers = 4

# Batch-Gr√∂√üe beim Ingestieren
ingest_batch_size = 10

# Retry-Konfiguration
[hypatia.datasources.retry]
max_attempts = 3
initial_backoff = "1s"
max_backoff = "1m"
```

---

## Benutzeroberfl√§che (TUI)

### Verzeichnis hinzuf√ºgen

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Datenquelle hinzuf√ºgen                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                      ‚îÇ
‚îÇ  Name:        [Projektdokumentation_________________]               ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  Verzeichnisse:                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ /Users/mikes/Documents/Projekt                                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ /Users/mikes/Notes                                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                          [+ Add]‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  Optionen:                                                           ‚îÇ
‚îÇ  [x] Unterverzeichnisse einschlie√üen                                ‚îÇ
‚îÇ  [ ] Nur bestimmte Dateitypen: [.md, .txt, .pdf_______________]     ‚îÇ
‚îÇ  [ ] Muster ausschlie√üen:      [node_modules, .git__________]       ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  Sync-Modus:                                                         ‚îÇ
‚îÇ  (‚Ä¢) Echtzeit (Watch)                                               ‚îÇ
‚îÇ  ( ) Polling alle [5] Minuten                                       ‚îÇ
‚îÇ  ( ) Nur manuell                                                    ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  Ziel-Collection: [projekt-docs________________] [Neu erstellen]   ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ                        [Abbrechen]  [Hinzuf√ºgen]                    ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Datenquellen-√úbersicht

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Datenquellen                         [+ Neu] ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ üìÅ Projektdokumentation                              [Active]  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    /Users/mikes/Documents/Projekt                              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    /Users/mikes/Notes                                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    üìä 245 Dateien (198 indexiert, 47 ausstehend)              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    üïê Letzte Sync: vor 2 Minuten                              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                              [Sync] [Pausieren] [Bearbeiten]   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ üìÅ Technische Dokumentation                          [Paused]  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    /Users/mikes/Docs/Technical                                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    üìä 1.203 Dateien (1.203 indexiert)                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    üïê Letzte Sync: vor 1 Tag                                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                            [Sync] [Fortsetzen] [Bearbeiten]    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ üìÅ Pers√∂nliche Notizen                           [Scanning...] ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    /Users/mikes/Personal/Notes                                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  67% (402/600)‚îÇ ‚îÇ
‚îÇ  ‚îÇ    ‚è±Ô∏è  Gesch√§tzte Restzeit: 2 Minuten                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                   [Abbrechen]  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Fehlerbehandlung

### Retry-Strategie

```go
type RetryConfig struct {
    MaxAttempts    int           // Maximale Versuche
    InitialBackoff time.Duration // Initiale Wartezeit
    MaxBackoff     time.Duration // Maximale Wartezeit
    Multiplier     float64       // Backoff-Multiplikator
}

// Exponential Backoff mit Jitter
func (r *RetryConfig) NextBackoff(attempt int) time.Duration {
    backoff := float64(r.InitialBackoff) * math.Pow(r.Multiplier, float64(attempt))
    if backoff > float64(r.MaxBackoff) {
        backoff = float64(r.MaxBackoff)
    }
    // Jitter: ¬±25%
    jitter := backoff * (0.75 + 0.5*rand.Float64())
    return time.Duration(jitter)
}
```

### Fehlertypen

| Fehler | Behandlung | Retry |
|--------|------------|-------|
| Datei nicht lesbar | In Error-Queue, User benachrichtigen | Nein |
| Datei gesperrt | Warten, sp√§ter erneut versuchen | Ja (3x) |
| Parser-Fehler | In Error-Queue, ggf. als Text fallback | Nein |
| Embedding-Fehler | Retry mit Backoff | Ja (5x) |
| Speicher-Fehler | Retry mit Backoff, ggf. Admin-Alert | Ja (10x) |
| Verzeichnis nicht erreichbar | Datenquelle pausieren, User benachrichtigen | Nein |

---

## Sicherheits√ºberlegungen

### Berechtigungen

1. **Lese-Berechtigungen**: Nur Verzeichnisse mit Leseberechtigung k√∂nnen hinzugef√ºgt werden
2. **Symlink-Pr√ºfung**: Symlinks werden aufgel√∂st und auf Zyklus gepr√ºft
3. **Path Traversal**: Pfade werden normalisiert und validiert

### Sensible Daten

```go
// SensitivePatterns sind Muster f√ºr sensible Dateien
var SensitivePatterns = []string{
    "*.pem",
    "*.key",
    "*.p12",
    "*.pfx",
    "*password*",
    "*secret*",
    "*credential*",
    ".env",
    ".env.*",
    "*.kdbx",      // KeePass
    "id_rsa*",
    "id_ed25519*",
}

// WarnIfSensitive pr√ºft auf sensible Dateien
func WarnIfSensitive(path string) bool {
    for _, pattern := range SensitivePatterns {
        if matched, _ := filepath.Match(pattern, filepath.Base(path)); matched {
            return true
        }
    }
    return false
}
```

---

## Implementierungsplan

### Phase 1: Grundger√ºst (1-2 Wochen)
- [ ] DataSource Interface definieren
- [ ] FilesystemSource implementieren (ohne Watch)
- [ ] FileState Datenbank (SQLite)
- [ ] Basic Scanner mit Filter
- [ ] Integration mit bestehendem Ingest

### Phase 2: Synchronisation (1 Woche)
- [ ] fsnotify Integration
- [ ] √Ñnderungserkennung
- [ ] Polling-Modus als Fallback
- [ ] Sync-Status Tracking

### Phase 3: Parser (1-2 Wochen)
- [ ] Text/Markdown Parser
- [ ] HTML Parser
- [ ] PDF Parser
- [ ] DOCX Parser
- [ ] Parser-Registry

### Phase 4: API & UI (1 Woche)
- [ ] gRPC Service erweitern
- [ ] REST Endpoints in Kant
- [ ] TUI f√ºr Datenquellen-Management

### Phase 5: Hardening (1 Woche)
- [ ] Cross-Platform Tests
- [ ] Error Handling & Retry
- [ ] Performance-Optimierung
- [ ] Dokumentation

---

## Design-Entscheidungen

Die folgenden Entscheidungen wurden getroffen:

### 1. Gro√üe Dateien
| Aspekt | Entscheidung |
|--------|--------------|
| **Verhalten** | Konfigurierbar pro Datenquelle |
| **Standard-Limit** | 100 MB |
| **√úberschreitung** | Datei wird √ºbersprungen mit Warnung im Log |
| **Konfiguration** | `max_file_size` in Datenquellen-Config |

```go
// Beispiel-Konfiguration
FilesystemConfig{
    MaxFileSize: 100 * 1024 * 1024, // 100 MB (Default)
}
```

### 2. Duplikate innerhalb einer Datenquelle
| Aspekt | Entscheidung |
|--------|--------------|
| **Verhalten** | Hash-basierte Deduplizierung |
| **Speicherung** | Ein Dokument, mehrere Pfade in Metadaten |
| **Erkennung** | SHA-256 Hash des Dateiinhalts |

```go
// FileState mit mehreren Pfaden
type FileState struct {
    Hash      string   // SHA-256
    Paths     []string // Alle Pfade zur gleichen Datei
    DocumentID string  // Ein Dokument in Hypatia
}
```

### 3. Duplikate √ºber Datenquellen hinweg (Cross-Source)
| Aspekt | Entscheidung |
|--------|--------------|
| **Verhalten** | Separate Dokumente in separaten Collections |
| **Deduplizierung** | Keine automatische Deduplizierung |
| **Begr√ºndung** | Unterschiedlicher Kontext, unterschiedliche Suchbereiche |

### 4. Versionierung
| Aspekt | Entscheidung |
|--------|--------------|
| **v1.0** | Keine Versionierung - immer √ºberschreiben |
| **Sp√§ter** | Optionale Versionierung als Feature geplant |
| **Bei √Ñnderung** | Altes Dokument l√∂schen, neues erstellen |

### 5. Bin√§rdateien (Bilder, Videos, etc.)
| Aspekt | Entscheidung |
|--------|--------------|
| **v1.0** | Ignorieren (nicht indizieren) |
| **Sp√§ter geplant** | Metadaten-Extraktion (EXIF, ID3, etc.) |
| **Sp√§ter geplant** | OCR f√ºr Bilder mit Text |
| **Sp√§ter geplant** | Audio-Transkription |

```go
// Bin√§rdatei-Erkennung
var BinaryExtensions = []string{
    // Bilder
    ".jpg", ".jpeg", ".png", ".gif", ".bmp", ".webp", ".svg",
    // Audio
    ".mp3", ".wav", ".flac", ".ogg", ".m4a",
    // Video
    ".mp4", ".avi", ".mkv", ".mov", ".webm",
    // Archive
    ".zip", ".tar", ".gz", ".rar", ".7z",
    // Ausf√ºhrbare
    ".exe", ".dll", ".so", ".dylib",
}
```

---

## Abh√§ngigkeiten

| Paket | Version | Zweck |
|-------|---------|-------|
| `github.com/fsnotify/fsnotify` | v1.7+ | File Watching |
| `github.com/yuin/goldmark` | v1.6+ | Markdown Parsing |
| `github.com/pdfcpu/pdfcpu` | v0.6+ | PDF Parsing |
| `github.com/unidoc/unioffice` | v1.30+ | Office-Dokumente |
| `golang.org/x/net/html` | latest | HTML Parsing |
| `github.com/mattn/go-sqlite3` | v1.14+ | State Database |
